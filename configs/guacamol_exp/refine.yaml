# @package _global_
dataset:
    name: 'expanded_guacamol'          
    datadir: '../data/guacamol/guacamol_pyg/'
    graph_type: 'expand'
    reduction_type: custom
    structual_dist: True
    split_ring: True
    filter: True
    charged: True
    
    num_processes: 4
    random_subset: null
    pin_memory: False

general:
    name : 'expanded_guacamol_custom'
    gpus : 1
    wandb: 'offline'
    resample_step: 1
    skip: 1
    # remove_h: False
    resume: /data2/chensm22/HRS/HierDigress_ckpts/checkpoints/guacamol/charged/guacamol.ckpt
    test_only: null
    check_val_every_n_epochs: 1
    val_check_interval: null
    sample_every_val: 20
    samples_to_generate: 256
    samples_to_save: 20
    chains_to_save: 5
    log_every_steps: 50

    final_model_samples_to_generate: 25000
    final_model_samples_to_save: 50
    final_model_chains_to_save: 20

train:
    optimizer: adamw
    n_epochs: 200
    batch_size: 96
    save_model: True
    lr: 1e-4
    devices: [0]
    num_workers: 4
model:
    n_layers: 12
    lambda_train: [5, 0]
    type: 'discrete'
    transition: 'masked_marginal'                          # uniform or marginal
    model: 'graph_tf'
    diffusion_steps: 500
    diffusion_noise_schedule: 'cosine'              # 'cosine', 'polynomial_2'
    extra_features: 'all'                              # 'all', 'cycles', 'eigenvalues' or null

  # Do not set hidden_mlp_E, dim_ffE too high, computing large tensors on the edges is costly
  # At the moment (03/08), y contains quite little information
    hidden_mlp_dims: { 'X': 256, 'E': 128, 'y': 256}

  # The dimensions should satisfy dx % n_head == 0
    hidden_dims: { 'dx': 256, 'de': 64, 'dy': 128, 'n_head': 8, 'dim_ffX': 256, 'dim_ffE': 128, 'dim_ffy': 256}
